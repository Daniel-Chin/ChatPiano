{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:47:44.476712Z",
     "start_time": "2024-09-26T15:47:42.306967Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "instructions = \"\"\"\n",
    "As a seasoned musician, I excel at transforming general instructions into meticulously crafted musical terminology. My expertise lies in interpreting creative directions and translating them into precise musical elements, whether it be phrasing, dynamics, articulation, or orchestration. Based on the flag you choose, I will adapt my response accordingly:\n",
    "\n",
    "---\n",
    "\n",
    "### **Flag 1 (Generating)**\n",
    "In this mode, I will convert your music-related instructions into detailed music-specific language, following a set structure that includes the following elements:\n",
    "\n",
    "1. **Meter and Tempo**: Time signature and the pace (e.g., \"4/4 time signature,\" \"moderate tempo\").\n",
    "2. **Duration**: Total playtime of the music (e.g., \"40 seconds,\" \"31 ~ 45 seconds\").\n",
    "3. **Pitch Range**: Octave range and its impact on the music (e.g., \"limited pitch range of 5 octaves\").\n",
    "4. **Key**: Tonality of the music (e.g., \"major key,\" \"minor key\").\n",
    "5. **Instrumental Arrangement**: The instruments used and their role in the piece (e.g., \"grand piano, guitar, bass, violin, synthesizer, and drum\").\n",
    "6. **Musical Character/Emotion**: Descriptive terms about the mood or feeling of the music (e.g., \"energetic beat,\" \"filled with chill\").\n",
    "7. **Structural Elements**: Number of bars and other compositional elements (e.g., \"13 ~ 16 bars\").\n",
    "8. **Style or Genre Influence**: Specific styles or influences that define the music (e.g., \"pop sound,\" \"classical genre\").\n",
    "9. **Additional Descriptive Elements**: Any unique qualities or character of the music (e.g., \"vibrant and dynamic sound,\" \"powerful and intense atmosphere\").\n",
    "\n",
    "This structured response helps generate a consistent, music-centric description that can be easily translated into technical or creative work.\n",
    "\n",
    "---\n",
    "\n",
    "**Template for Music Description:**\n",
    "\n",
    "1. **Time Signature and Tempo:**\n",
    "   - Example: \"The composition is in a 4/4 time signature and is played at a moderate tempo.\"\n",
    "\n",
    "2. **Duration:**\n",
    "   - Example: \"The piece lasts approximately 40 seconds.\"\n",
    "\n",
    "3. **Pitch Range:**\n",
    "   - Example: \"The limited pitch range of 5 octaves allows for nuanced expression in tone and phrasing.\"\n",
    "\n",
    "4. **Key and Tonality:**\n",
    "   - Example: \"Composed in a minor key, the piece evokes a resonant and introspective sound.\"\n",
    "\n",
    "5. **Instrumentation:**\n",
    "   - Example: \"The music features a grand piano, guitar, bass, violin, synthesizer, and drums, each contributing to its distinct sonic character.\"\n",
    "\n",
    "6. **Mood and Emotional Character:**\n",
    "   - Example: \"The music is characterized by a lively and dynamic mood, creating a sense of delight and energy.\"\n",
    "\n",
    "7. **Structure and Form:**\n",
    "   - Example: \"The composition unfolds over 13 to 16 bars.\"\n",
    "\n",
    "8. **Style or Genre Influence:**\n",
    "   - Example: \"The piece is influenced by pop music, blending modern elements with a traditional structure.\"\n",
    "\n",
    "9. **Additional Descriptive Details:**\n",
    "   - Example: \"The rapid tempo combined with a distinctive rhythmic pattern creates an engaging and memorable listening experience.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Example Query**: I want a happy music:\n",
    "**Example Response**: \n",
    "The composition is set in a 4/4 meter, played at a lively and upbeat tempo, and spans approximately 35 seconds. The music is in a major key, which creates a bright and joyful atmosphere. It features a pitch range of 5 octaves, allowing for dynamic variation and energetic expression. The instrumental arrangement includes grand piano, acoustic guitar, bass, violin, and drums, each contributing to a vibrant and uplifting sound. The structure unfolds over 12 to 14 bars, and the cheerful rhythm, influenced by pop and folk genres, gives the music a catchy and engaging quality. This piece is defined by its playful mood and celebratory character, making it a memorable and enjoyable listening experience.\n",
    "\n",
    "---\n",
    "\n",
    "### **Flag 2 (Casual Chat)**\n",
    "In this mode, I will engage in casual conversation about music or general topics. I can provide friendly and informative answers that do not require the structured music description.\n",
    "\n",
    "For example, you may ask for general music advice, personal experiences with music, or even non-music-related casual conversations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Function Control Commands**\n",
    "In addition to handling music instructions, I can also perform actions related to the **Music X Machine**, the underlying music-tutoring system. Here are the three available functions I can execute:\n",
    "\n",
    "1. **Wait**: Do nothing and wait for further stimuli, such as the student speaking or playing music.\n",
    "2. **StartSession**: Start a Practice Session on Music X Machine. Do not call this function unless all modes are already set.\n",
    "3. **InterruptSession**: Immediately end the Practice Session on Music X Machine. Call this when the student is having trouble or has started speaking in the middle of a Session.\n",
    "\n",
    "---\n",
    "\n",
    "In **Flag 1**, you can ask for a music description, and I will return a paragraph following the template.\n",
    "In **Flag 2**, you can ask general questions or request to perform one of the available commands (e.g., \"StartSession\").\n",
    "\n",
    "**Function Query Example**:\n",
    "- Query: Start a new session.\n",
    "- Response: Executing StartSession... Starting Practice Session on Music X Machine...\n",
    "\n",
    "Use the flags to guide the conversation. Let me know if you want to generate music-specific instructions or engage in casual chat!\n",
    "\"\"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "text2text_client = OpenAI(api_key=\"\")\n",
    "\n",
    "assistant = text2text_client.beta.assistants.create(\n",
    "  name=\"Chat Piano\",\n",
    "  instructions=instructions,\n",
    "  tools=[],\n",
    "  model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "thread = text2text_client.beta.threads.create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:47:44.749416Z",
     "start_time": "2024-09-26T15:47:44.477716Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "class TextToMidiClient:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "\n",
    "    def submit_text(self, text):\n",
    "        url = f\"{self.base_url}/submit-text\"\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        data = {'text': text}\n",
    "\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def check_status(self, job_id):\n",
    "        url = f\"{self.base_url}/check-status/{job_id}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def get_result(self, job_id):\n",
    "        url = f\"{self.base_url}/get-result/{job_id}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def download_midi(self, job_id, save_path):\n",
    "        url = f\"{self.base_url}/download-midi/{job_id}\"\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        return save_path\n",
    "    \n",
    "# Initialize the client with the base URL of your Flask server\n",
    "text2midi_client = TextToMidiClient(base_url=\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:47:44.753897Z",
     "start_time": "2024-09-26T15:47:44.750419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define an assistant tool to handle music conversion\n",
    "def convert_text_to_midi(text_command):\n",
    "    try:\n",
    "        # Step 1: Submit text for MIDI conversion\n",
    "        submit_response = text2midi_client.submit_text(text_command)\n",
    "        job_id = submit_response['jobId']\n",
    "        print(f\"Job submitted. Job ID: {job_id}\")\n",
    "\n",
    "        # Step 2: Poll the job status until it's completed\n",
    "        while True:\n",
    "            status_response = text2midi_client.check_status(job_id)\n",
    "            status = status_response['status']\n",
    "            print(f\"Job Status: {status}\")\n",
    "            if status == 'completed':\n",
    "                break\n",
    "            elif status == 'failed':\n",
    "                print(\"Job failed.\")\n",
    "                return None\n",
    "            time.sleep(2)  # Wait for 2 seconds before checking again\n",
    "\n",
    "        # Step 3: Retrieve the result (metadata)\n",
    "        result_response = text2midi_client.get_result(job_id)\n",
    "        meta_data = result_response['metaData']\n",
    "        print(\"Metadata:\")\n",
    "        print(meta_data)\n",
    "\n",
    "        # Step 4: Download the MIDI file\n",
    "        midi_file_path = text2midi_client.download_midi(job_id, save_path=f\"storage/{job_id}.mid\")\n",
    "        print(f\"MIDI file downloaded to {midi_file_path}\")\n",
    "\n",
    "        return midi_file_path, meta_data\n",
    "\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err.response.json()}\")\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:47:44.757453Z",
     "start_time": "2024-09-26T15:47:44.754905Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_input(input_text):\n",
    "    \"\"\"Process input based on flag mode and send to assistant.\"\"\"\n",
    "    message = text2text_client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=input_text\n",
    "    )\n",
    "\n",
    "    run = text2text_client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id\n",
    "    )\n",
    "    \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:47:44.766663Z",
     "start_time": "2024-09-26T15:47:44.758457Z"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Assuming previously defined TextToMidiClient and text2midi_client\n",
    "\n",
    "# Class to control Music X Machine\n",
    "class ControlMusicX:\n",
    "    def __init__(self):\n",
    "        self.session_active = False\n",
    "\n",
    "    def start_session(self):\n",
    "        if not self.session_active:\n",
    "            print(\"Starting Practice Session on Music X Machine...\")\n",
    "            self.session_active = True\n",
    "        else:\n",
    "            print(\"Session is already active.\")\n",
    "\n",
    "    def interrupt_session(self):\n",
    "        if self.session_active:\n",
    "            print(\"Interrupting Practice Session on Music X Machine...\")\n",
    "            self.session_active = False\n",
    "        else:\n",
    "            print(\"No session to interrupt.\")\n",
    "\n",
    "    def wait(self):\n",
    "        print(\"Waiting for further stimuli...\")\n",
    "\n",
    "# Initialize ControlMusicX\n",
    "music_x = ControlMusicX()\n",
    "\n",
    "def handle_midi_conversion(text_command, result_queue):\n",
    "    \"\"\"Thread function to handle MIDI conversion and store results.\"\"\"\n",
    "    midi_result = convert_text_to_midi(text_command)\n",
    "    result_queue.put(midi_result)  # Place the result in a queue for the main thread to retrieve.\n",
    "\n",
    "def detect_commands(ai_response):\n",
    "    \"\"\"Detect commands in AI response and handle them.\"\"\"\n",
    "    if re.search(r'\\bStartSession\\b', ai_response, re.IGNORECASE):\n",
    "        music_x.start_session()\n",
    "        return \"StartSession\"\n",
    "    elif re.search(r'\\bInterruptSession\\b', ai_response, re.IGNORECASE):\n",
    "        music_x.interrupt_session()\n",
    "        return \"InterruptSession\"\n",
    "    elif re.search(r'\\bWait\\b', ai_response, re.IGNORECASE):\n",
    "        music_x.wait()\n",
    "        return \"Wait\"\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    conversion_thread = None\n",
    "    result_queue = queue.Queue()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Check if there's a MIDI conversion in progress\n",
    "            if conversion_thread and conversion_thread.is_alive():\n",
    "                # Optionally, inform the user about the conversion status\n",
    "                print(\"MIDI conversion is in progress...\")\n",
    "            else:\n",
    "                # If the MIDI conversion has finished, handle the result\n",
    "                if conversion_thread and not conversion_thread.is_alive():\n",
    "                    if not result_queue.empty():\n",
    "                        midi_result = result_queue.get()\n",
    "                        if midi_result:\n",
    "                            midi_file_path, meta_data = midi_result\n",
    "                            print(f\"MIDI file saved at: {midi_file_path}\")\n",
    "                            print(\"Metadata: \", meta_data)\n",
    "                        else:\n",
    "                            print(\"MIDI conversion failed.\")\n",
    "                        conversion_thread = None  # Reset the thread\n",
    "            # Get user input\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() == 'exit':\n",
    "                break\n",
    "            # Prepare the assistant input without exposing flags to the user\n",
    "            assistant_input = \"Flag 2: \" + user_input\n",
    "            # Send input to the assistant\n",
    "            run = process_input(assistant_input)\n",
    "\n",
    "            if run.status == 'completed':\n",
    "                messages = text2text_client.beta.threads.messages.list(thread_id=thread.id)\n",
    "                ai_response = messages.data[-1].content[0].text.value  # Get the latest response\n",
    "                print(\"Assistant:\", ai_response)\n",
    "\n",
    "                # Detect commands in the AI response\n",
    "                command = detect_commands(ai_response)\n",
    "\n",
    "                if command == \"StartSession\":\n",
    "                    # In generating mode, the assistant provides the music description\n",
    "                    # Get user input\n",
    "                    user_input = input(\"You: \")\n",
    "                    # Prepare the assistant input without exposing flags to the user\n",
    "                    assistant_input = \"Flag 1: \" + user_input + \"[return the instruction only, do not contain any further instruction about the way it plays, only generate 10 seconds.]\"\n",
    "                    # Send input to the assistant\n",
    "                    run = process_input(assistant_input)\n",
    "                    if run.status == 'completed':\n",
    "                        messages = text2text_client.beta.threads.messages.list(thread_id=thread.id)\n",
    "                        ai_response = messages.data[-1].content[0].text.value  # Get the latest response\n",
    "                        print(\"Assistant:\", ai_response)\n",
    "                        # Start the MIDI conversion using the assistant's response\n",
    "                        conversion_thread = threading.Thread(target=handle_midi_conversion, args=(ai_response, result_queue))\n",
    "                        conversion_thread.start()\n",
    "                elif command == \"InterruptSession\":\n",
    "                    pass\n",
    "                elif command == \"Wait\":\n",
    "                    pass\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                print(f\"Assistant run status: {run.status}\")\n",
    "\n",
    "            # Allow some time before the next iteration to prevent overwhelming the assistant\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Program exited by user.\")\n",
    "\n",
    "    # Ensure that any remaining thread is completed before exiting\n",
    "    if conversion_thread and conversion_thread.is_alive():\n",
    "        conversion_thread.join()\n",
    "        if not result_queue.empty():\n",
    "            midi_result = result_queue.get()\n",
    "            if midi_result:\n",
    "                midi_file_path, meta_data = midi_result\n",
    "                print(f\"MIDI file saved at: {midi_file_path}\")\n",
    "                print(\"Metadata: \", meta_data)\n",
    "            else:\n",
    "                print(\"MIDI conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-26T15:47:44.766663Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Flag 2: 1\n",
      "Assistant run status: failed\n",
      "Assistant: Flag 2: 1\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MuseCoco-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
